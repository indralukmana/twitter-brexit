{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column that I want to use: <br />\n",
    "Twitter Data<br />\n",
    "created_at | id | User.screen_name | Text | Lang | retweet_count | reply_count | quote_count | retweeted_status | <br /><br />\n",
    "\n",
    "Sentiment Analysis<br />\n",
    "sentiment polarity |\n",
    "\n",
    "BotOMeter<br />\n",
    "screen_name | english | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preparation</h1>\n",
    "<h3>Data Preparation #1: Import twitter data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"../input/2017-09-22.tar.gz\", \"r:gz\")\n",
    "data = pd.DataFrame()\n",
    "count=0\n",
    "\n",
    "'''\n",
    "        Extracting from twitter data.\n",
    "'''\n",
    "\n",
    "for members in tar.getmembers():\n",
    "    if (count==13):\n",
    "        f = tar.extractfile(members)\n",
    "        data = data.append(pd.read_json(f, lines=True))\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "        Compiling hashtags result.\n",
    "'''\n",
    "count=0\n",
    "hashtags=[]\n",
    "for ent in data['entities']:\n",
    "    str_hsh=''\n",
    "    for hsh in ent['hashtags']:\n",
    "        #print(hsh['text'])\n",
    "        str_hsh=hsh['text']+';'+str_hsh\n",
    "    hashtags.append(str_hsh.upper())\n",
    "    count = count+1\n",
    "    \n",
    "'''\n",
    "        Compiling user screen_name result.\n",
    "'''\n",
    "namelist=[]\n",
    "for x in data['user']:\n",
    "    namelist.append(x['screen_name'])\n",
    "\n",
    "twt_data=pd.DataFrame({'screen_name':namelist, 'lang':data['lang'] \n",
    "                            ,'retweet_count':data['retweet_count']\n",
    "                            ,'reply_count':data['reply_count']\n",
    "                            ,'quote_count':data['quote_count']\n",
    "                            ,'retweeted_status':data['retweeted_status']\n",
    "                            ,'hashtags':hashtags\n",
    "                            ,'created_at':data['created_at']\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contributors                                                               NaN\n",
       "coordinates                                                               None\n",
       "created_at                                                 2017-09-22 12:05:02\n",
       "display_text_range                                                    [0, 140]\n",
       "entities                     {u'user_mentions': [], u'symbols': [], u'hasht...\n",
       "extended_entities                                                          NaN\n",
       "extended_tweet               {u'display_text_range': [0, 135], u'entities':...\n",
       "favorite_count                                                               0\n",
       "favorited                                                                False\n",
       "filter_level                                                               low\n",
       "geo                                                                       None\n",
       "id                                                          911199659657498625\n",
       "id_str                                                      911199659657498624\n",
       "in_reply_to_screen_name                                                   None\n",
       "in_reply_to_status_id                                                      NaN\n",
       "in_reply_to_status_id_str                                                  NaN\n",
       "in_reply_to_user_id                                                        NaN\n",
       "in_reply_to_user_id_str                                                    NaN\n",
       "is_quote_status                                                          False\n",
       "lang                                                                        en\n",
       "place                                                                     None\n",
       "possibly_sensitive                                                           0\n",
       "quote_count                                                                  0\n",
       "quoted_status                                                              NaN\n",
       "quoted_status_id                                                           NaN\n",
       "quoted_status_id_str                                                       NaN\n",
       "reply_count                                                                  0\n",
       "retweet_count                                                                0\n",
       "retweeted                                                                False\n",
       "retweeted_status                                                           NaN\n",
       "source                       <a href=\"https://www.sociallymap.com\" rel=\"nof...\n",
       "text                         Less than 2 weeks away now from MRO Europe 201...\n",
       "timestamp_ms                                        2017-09-22 12:05:02.790000\n",
       "truncated                                                                 True\n",
       "user                         {u'follow_request_sent': None, u'profile_use_b...\n",
       "withheld_in_countries                                                      NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]\n",
    "#len(twt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Preparation #2: Import data from previous BotOMeter preprocessing </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bot_data = pd.DataFrame()\n",
    "\n",
    "for i in range(1,8):\n",
    "    output=\"outputbot_\"+str(i)+\".csv\"\n",
    "    bot_data=bot_data.append(pd.read_csv(output))[['screen_name','english']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3232\n"
     ]
    }
   ],
   "source": [
    "print(len(bot_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Preparation #3: Import Sentiment based on Naive Bayes data</h3>\n",
    "since the analysis process taking time, I decided to separate this process to another notebook file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_data = pd.DataFrame()\n",
    "sentiment_data = pd.read_csv(\"sentiment_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"As we wait anxiously for Mrs May's #Florence speech, has any Prime Minister in modern history inherited such a Herculean task as #Brexit?\""
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment_data)\n",
    "data.iloc[185]['text']\n",
    "#data.iloc[sentiment_data[sentiment_data['p_pos']>0.99].index]['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Merging: Merging the data sources</h1>\n",
    "since the analysis process taking time, I decided to separate this process to another notebook file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4369\n"
     ]
    }
   ],
   "source": [
    "sen_dat=twt_data.join(sentiment_data[['class','p_neg','p_pos']])\n",
    "\n",
    "compiled_data=pd.merge(sen_dat,bot_data, how='left', on=['screen_name'])\n",
    "print(len(compiled_data))\n",
    "\n",
    "#compiled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data checking process: </h3>\n",
    "since the analysis process taking time, I decided to separate this process to another notebook file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert (len(compiled_data)==len(data)), \"Input data and output data has a different count\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Describing the Data</h1>\n",
    "since the analysis process taking time, I decided to separate this process to another notebook file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analysis Part</h1>\n",
    "since the analysis Part taking time, I decided to separate this process to another notebook file. \n",
    "\n",
    "<h3>Analysis 1: sentiment analysis of hashtags</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt_tag=[]\n",
    "sntment_tag=[]\n",
    "for x in range(len(compiled_data)):\n",
    "    oo=TextBlob(compiled_data.iloc[x]['hashtags']).words\n",
    "    for p in oo:\n",
    "        txt_tag.append(p)\n",
    "        sntment_tag.append(compiled_data.iloc[x]['p_pos'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtag_analysis=pd.DataFrame({\n",
    "            'hashtag':txt_tag,\n",
    "            'sentimenttag':sntment_tag\n",
    "            })\n",
    "\n",
    "\n",
    "lol=hashtag_analysis.groupby(['hashtag'], as_index=False).mean()\n",
    "lol1=hashtag_analysis.groupby(['hashtag'], sort=True, as_index=False).count().sort_values(by='sentimenttag', ascending=False)\n",
    "#lol.index.names = ['hashtag']\n",
    "\n",
    "\n",
    "analysis1=pd.merge(lol,lol1, how='left', on=['hashtag'])\n",
    "analysis1=analysis1.rename(columns = {\n",
    "                            'sentimenttag_y':'count',\n",
    "                            'sentimenttag_x':'p_pos'\n",
    "                           })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>p_pos</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>BREXIT</td>\n",
       "      <td>0.704155</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>EU</td>\n",
       "      <td>0.676697</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>REFERENDUM</td>\n",
       "      <td>0.655990</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>EUROPE</td>\n",
       "      <td>0.795995</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>FLORENCESPEECH</td>\n",
       "      <td>0.778298</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>0.917295</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>STOPBREXIT</td>\n",
       "      <td>0.696550</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>WALKAWAYMAY</td>\n",
       "      <td>0.702781</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>REMAIN</td>\n",
       "      <td>0.678516</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>THERESAMAY</td>\n",
       "      <td>0.672287</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>REFUGEESWELCOME</td>\n",
       "      <td>0.596255</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>UK</td>\n",
       "      <td>0.734290</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1OCT</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1O</td>\n",
       "      <td>0.900449</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>NEWS</td>\n",
       "      <td>0.604795</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>CATALONIA</td>\n",
       "      <td>0.543919</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>LIBRE</td>\n",
       "      <td>0.969404</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>DEMOCRACY</td>\n",
       "      <td>0.964863</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>NOBREXIT</td>\n",
       "      <td>0.647117</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>UKIP</td>\n",
       "      <td>0.696066</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>BARGAININGCHIPS</td>\n",
       "      <td>0.655540</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>LIBERTY</td>\n",
       "      <td>0.975140</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>BBCQT</td>\n",
       "      <td>0.562666</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>UBER</td>\n",
       "      <td>0.229999</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>SCOTREF</td>\n",
       "      <td>0.553796</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>LEAVE</td>\n",
       "      <td>0.613106</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>CATALUNYA</td>\n",
       "      <td>0.533178</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>BREXITSHAMBLES</td>\n",
       "      <td>0.604266</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>CONSERVATIVES</td>\n",
       "      <td>0.822175</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>EUREFERENDUM</td>\n",
       "      <td>0.989430</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>NO2EU</td>\n",
       "      <td>0.989430</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>EUROPEUNION</td>\n",
       "      <td>0.531131</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>UN</td>\n",
       "      <td>0.645137</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>MAY</td>\n",
       "      <td>0.719509</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>0.835041</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BBC</td>\n",
       "      <td>0.796555</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>LONDON</td>\n",
       "      <td>0.745588</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>US</td>\n",
       "      <td>0.697172</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>WORLD</td>\n",
       "      <td>0.807106</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>USA</td>\n",
       "      <td>0.813153</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>BREXITFORENSICS</td>\n",
       "      <td>0.520387</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>SYRIA</td>\n",
       "      <td>0.808317</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>0.434656</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>NYC</td>\n",
       "      <td>0.396918</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>VOTAREM</td>\n",
       "      <td>0.641160</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>RUSSIA</td>\n",
       "      <td>0.949475</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>TCOT</td>\n",
       "      <td>0.861010</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>CATALUÑA</td>\n",
       "      <td>0.446758</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>HUMANRIGHTS</td>\n",
       "      <td>0.700335</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.720374</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              hashtag     p_pos  count\n",
       "199            BREXIT  0.704155   1858\n",
       "556                EU  0.676697    745\n",
       "1385       REFERENDUM  0.655990    434\n",
       "575            EUROPE  0.795995    294\n",
       "654    FLORENCESPEECH  0.778298    230\n",
       "653          FLORENCE  0.917295    198\n",
       "1572       STOPBREXIT  0.696550    181\n",
       "1820      WALKAWAYMAY  0.702781    163\n",
       "1399           REMAIN  0.678516    116\n",
       "1638       THERESAMAY  0.672287    109\n",
       "1391  REFUGEESWELCOME  0.596255     92\n",
       "1728               UK  0.734290     84\n",
       "3                1OCT  0.588563     69\n",
       "2                  1O  0.900449     67\n",
       "1184             NEWS  0.604795     62\n",
       "266         CATALONIA  0.543919     57\n",
       "1024            LIBRE  0.969404     54\n",
       "425         DEMOCRACY  0.964863     47\n",
       "1202         NOBREXIT  0.647117     47\n",
       "1730             UKIP  0.696066     46\n",
       "127   BARGAININGCHIPS  0.655540     46\n",
       "1022          LIBERTY  0.975140     45\n",
       "139             BBCQT  0.562666     42\n",
       "1723             UBER  0.229999     40\n",
       "1475          SCOTREF  0.553796     40\n",
       "1009            LEAVE  0.613106     40\n",
       "270         CATALUNYA  0.533178     39\n",
       "213    BREXITSHAMBLES  0.604266     39\n",
       "345     CONSERVATIVES  0.822175     39\n",
       "566      EUREFERENDUM  0.989430     39\n",
       "1200            NO2EU  0.989430     39\n",
       "584       EUROPEUNION  0.531131     38\n",
       "1738               UN  0.645137     33\n",
       "1089              MAY  0.719509     32\n",
       "1680           TRAVEL  0.835041     29\n",
       "134               BBC  0.796555     29\n",
       "1047           LONDON  0.745588     29\n",
       "1765               US  0.697172     28\n",
       "1857            WORLD  0.807106     25\n",
       "1766              USA  0.813153     25\n",
       "208   BREXITFORENSICS  0.520387     24\n",
       "1604            SYRIA  0.808317     23\n",
       "126         BARCELONA  0.434656     23\n",
       "1231              NYC  0.396918     23\n",
       "1802          VOTAREM  0.641160     22\n",
       "1437           RUSSIA  0.949475     22\n",
       "1615             TCOT  0.861010     22\n",
       "272          CATALUÑA  0.446758     22\n",
       "840       HUMANRIGHTS  0.700335     21\n",
       "330               CNN  0.720374     21"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis1.sort_values(by=['count'], ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(compiled_data[pd.isnull(compiled_data['retweeted_status'])==True])\n",
    "#compiled_data[pd.isnull(compiled_data['english'])==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydict=Counter(namelist)\n",
    "\n",
    "for key, value in sorted(mydict.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    print \"%s: %s\" % (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hypotheses</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>hypothesis #1:</h3>\n",
    "Does the sentiment analysis in brexit like negative or positive exactly explain the context of the brexit?what is the meaning of positive sentiment in this case??\n",
    "naives bayes method classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>hypothesis #2:</h3>\n",
    "in order to know the chronology or the spread of thought the data should not only one hour time frame. it's supposed to be more than one hour time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>hypothesis #3:</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compiled_data[pd.isnull(compiled_data['retweeted_status'])==False]['retweeted_status']\n",
    "#print(len(compiled_data))\n",
    "#compiled_data.loc[4363]\n",
    "\n",
    "wordfreq=[]\n",
    "\n",
    "txt=TextBlob(compiled_data.iloc[0]['hashtags']).words\n",
    "wordfreq = [txt.count(p) for p in txt]\n",
    "zz = [compiled_data.iloc[0]['p_pos'] for x in txt]\n",
    "\n",
    "wordfreq_dict=dict(zip(txt,zz))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
