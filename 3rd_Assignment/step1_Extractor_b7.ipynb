{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# Pandas by default limit the maximum columns display. This will remove the limit.\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "tweets = []\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_filename = \"2016-06-23:05:34:01.json\"\n",
    "twitter_file = open(twitter_filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_columns = ['id_str',\n",
    "                    'created_at', \n",
    "                    'text', \n",
    "                    'entities.hashtags', \n",
    "                    'lang',\n",
    "                    'user.screen_name', \n",
    "                    'user.id_str',\n",
    "                    'user.followers_count',\n",
    "                    'user.friends_count',\n",
    "                    'retweeted_status.id_str',\n",
    "                    'retweeted_status.created_at',\n",
    "                    'retweeted_status.text',\n",
    "                    'retweeted_status.entities.hashtags',\n",
    "                    'retweeted_status.lang',\n",
    "                    'retweeted_status.user.screen_name',\n",
    "                    'retweeted_status.user.id_str',\n",
    "                    'retweeted_status.user.followers_count',\n",
    "                    'retweeted_status.user.friends_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame()\n",
    "with open(twitter_filename, 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        df = json_normalize(tweet)\n",
    "        df_tweets = df_tweets.append(df.loc[:,selected_columns], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_str                                   19851\n",
       "created_at                               19851\n",
       "text                                     19851\n",
       "entities.hashtags                        19851\n",
       "lang                                     19851\n",
       "user.screen_name                         19851\n",
       "user.id_str                              19851\n",
       "user.followers_count                     19851\n",
       "user.friends_count                       19851\n",
       "retweeted_status.id_str                  11265\n",
       "retweeted_status.created_at              11265\n",
       "retweeted_status.text                    11265\n",
       "retweeted_status.entities.hashtags       11265\n",
       "retweeted_status.lang                    11265\n",
       "retweeted_status.user.screen_name        11265\n",
       "retweeted_status.user.id_str             11265\n",
       "retweeted_status.user.followers_count    11265\n",
       "retweeted_status.user.friends_count      11265\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_hashtags(entries):\n",
    "    hashtags = []\n",
    "#     print (entries)\n",
    "    if (entries != \"NO HASHTAGS\"): \n",
    "        if (len(entries) == 0):\n",
    "            return \"NO HASHTAGS\"\n",
    "        else:\n",
    "            for entry in entries: # for each line in our input\n",
    "    #             print(entry['text'])\n",
    "    #             for ht in entry: # for every hashtag in each line\n",
    "    #                 print (ht)\n",
    "                hashtags.append(entry['text'])\n",
    "            return hashtags\n",
    "    else:\n",
    "        return \"NO HASHTAGS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets['entities.hashtags'] = df_tweets['entities.hashtags'].astype('object').fillna(\"No Hashtags\")\n",
    "df_tweets['retweeted_status.entities.hashtags'] = df_tweets['retweeted_status.entities.hashtags'].astype('object').fillna(\"NO HASHTAGS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tweets['retweeted_status.entities.hashtags'] = df_tweets['retweeted_status.entities.hashtags'].apply(lambda row: convert_hashtags(row))\n",
    "df_tweets['entities.hashtags'] = df_tweets['entities.hashtags'].apply(lambda row: convert_hashtags(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tweets.to_csv(\"export_2016062306.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets2 = pd.read_csv('export_2016062306.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Thu Jun 23 04:34:03 +0000 2016\n",
       "1        Thu Jun 23 04:34:03 +0000 2016\n",
       "2        Thu Jun 23 04:34:04 +0000 2016\n",
       "3        Thu Jun 23 04:34:04 +0000 2016\n",
       "4        Thu Jun 23 04:34:04 +0000 2016\n",
       "5        Thu Jun 23 04:34:05 +0000 2016\n",
       "6        Thu Jun 23 04:34:05 +0000 2016\n",
       "7        Thu Jun 23 04:34:05 +0000 2016\n",
       "8        Thu Jun 23 04:34:05 +0000 2016\n",
       "9        Thu Jun 23 04:34:05 +0000 2016\n",
       "10       Thu Jun 23 04:34:05 +0000 2016\n",
       "11       Thu Jun 23 04:34:06 +0000 2016\n",
       "12       Thu Jun 23 04:34:06 +0000 2016\n",
       "13       Thu Jun 23 04:34:06 +0000 2016\n",
       "14       Thu Jun 23 04:34:06 +0000 2016\n",
       "15       Thu Jun 23 04:34:07 +0000 2016\n",
       "16       Thu Jun 23 04:34:07 +0000 2016\n",
       "17       Thu Jun 23 04:34:07 +0000 2016\n",
       "18       Thu Jun 23 04:34:08 +0000 2016\n",
       "19       Thu Jun 23 04:34:08 +0000 2016\n",
       "20       Thu Jun 23 04:34:08 +0000 2016\n",
       "21       Thu Jun 23 04:34:08 +0000 2016\n",
       "22       Thu Jun 23 04:34:08 +0000 2016\n",
       "23       Thu Jun 23 04:34:08 +0000 2016\n",
       "24       Thu Jun 23 04:34:08 +0000 2016\n",
       "25       Thu Jun 23 04:34:08 +0000 2016\n",
       "26       Thu Jun 23 04:34:08 +0000 2016\n",
       "27       Thu Jun 23 04:34:08 +0000 2016\n",
       "28       Thu Jun 23 04:34:08 +0000 2016\n",
       "29       Thu Jun 23 04:34:09 +0000 2016\n",
       "                      ...              \n",
       "19821    Thu Jun 23 05:33:58 +0000 2016\n",
       "19822    Thu Jun 23 05:33:58 +0000 2016\n",
       "19823    Thu Jun 23 05:33:57 +0000 2016\n",
       "19824    Thu Jun 23 05:33:58 +0000 2016\n",
       "19825    Thu Jun 23 05:33:58 +0000 2016\n",
       "19826    Thu Jun 23 05:33:58 +0000 2016\n",
       "19827    Thu Jun 23 05:33:58 +0000 2016\n",
       "19828    Thu Jun 23 05:33:58 +0000 2016\n",
       "19829    Thu Jun 23 05:33:58 +0000 2016\n",
       "19830    Thu Jun 23 05:33:59 +0000 2016\n",
       "19831    Thu Jun 23 05:33:59 +0000 2016\n",
       "19832    Thu Jun 23 05:33:58 +0000 2016\n",
       "19833    Thu Jun 23 05:33:59 +0000 2016\n",
       "19834    Thu Jun 23 05:33:59 +0000 2016\n",
       "19835    Thu Jun 23 05:33:59 +0000 2016\n",
       "19836    Thu Jun 23 05:33:59 +0000 2016\n",
       "19837    Thu Jun 23 05:34:00 +0000 2016\n",
       "19838    Thu Jun 23 05:33:59 +0000 2016\n",
       "19839    Thu Jun 23 05:34:00 +0000 2016\n",
       "19840    Thu Jun 23 05:34:00 +0000 2016\n",
       "19841    Thu Jun 23 05:34:00 +0000 2016\n",
       "19842    Thu Jun 23 05:34:00 +0000 2016\n",
       "19843    Thu Jun 23 05:34:00 +0000 2016\n",
       "19844    Thu Jun 23 05:34:00 +0000 2016\n",
       "19845    Thu Jun 23 05:34:00 +0000 2016\n",
       "19846    Thu Jun 23 05:34:00 +0000 2016\n",
       "19847    Thu Jun 23 05:34:01 +0000 2016\n",
       "19848    Thu Jun 23 05:34:01 +0000 2016\n",
       "19849    Thu Jun 23 05:34:01 +0000 2016\n",
       "19850    Thu Jun 23 05:34:01 +0000 2016\n",
       "Name: created_at, Length: 19874, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets2['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
